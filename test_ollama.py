#!/usr/bin/env python3
"""
Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import httpx
import asyncio
import json

async def test_ollama_connection():
    """Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Ollama ì„œë²„ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n")
    
    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    print("1. ì„œë²„ ìƒíƒœ í™•ì¸:")
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get("http://localhost:11434/api/tags")
            if response.status_code == 200:
                data = response.json()
                models = data.get('models', [])
                print(f"   âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘")
                print(f"   âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆ˜: {len(models)}")
                if models:
                    print("   ğŸ“‹ ëª¨ë¸ ëª©ë¡:")
                    for model in models[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                        print(f"      - {model.get('name')}")
                else:
                    print("   âš ï¸  ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    print("   ğŸ’¡ 'ollama pull llama3.2:3b' ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
            else:
                print(f"   âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
    except Exception as e:
        print(f"   âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("   ğŸ’¡ 'ollama serve' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return False
    
    # 2. Chat API í…ŒìŠ¤íŠ¸
    print("\n2. Chat API í…ŒìŠ¤íŠ¸:")
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            payload = {
                "model": "llama3.2:3b",
                "messages": [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”? ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”."}
                ],
                "stream": False
            }
            
            print("   ğŸš€ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
            response = await client.post(
                "http://localhost:11434/api/chat",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                message = data.get('message', {}).get('content', '')
                print(f"   âœ… ì‘ë‹µ ìˆ˜ì‹ : {message[:100]}...")
                return True
            else:
                print(f"   âŒ API ì˜¤ë¥˜: {response.status_code}")
                print(f"   ì‘ë‹µ: {response.text}")
    except httpx.TimeoutException:
        print("   âŒ ì‹œê°„ ì´ˆê³¼ - ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("   ğŸ’¡ 'ollama run llama3.2:3b' ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë¨¼ì € ì‹¤í–‰í•´ë³´ì„¸ìš”.")
    except Exception as e:
        print(f"   âŒ Chat API ì˜¤ë¥˜: {e}")
    
    return False

async def test_streaming():
    """ìŠ¤íŠ¸ë¦¬ë° API í…ŒìŠ¤íŠ¸"""
    print("\n3. ìŠ¤íŠ¸ë¦¬ë° API í…ŒìŠ¤íŠ¸:")
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            payload = {
                "model": "llama3.2:3b",
                "messages": [
                    {"role": "user", "content": "1ë¶€í„° 5ê¹Œì§€ ì„¸ì–´ì£¼ì„¸ìš”."}
                ],
                "stream": True
            }
            
            print("   ğŸš€ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì¤‘...")
            full_response = ""
            
            async with client.stream('POST', "http://localhost:11434/api/chat", json=payload) as response:
                async for line in response.aiter_lines():
                    if line:
                        try:
                            data = json.loads(line)
                            if 'message' in data:
                                content = data['message'].get('content', '')
                                full_response += content
                                print(f"   ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: {content}", end='', flush=True)
                        except json.JSONDecodeError:
                            pass
            
            print(f"\n   âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
            return True
            
    except Exception as e:
        print(f"   âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
        return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("ğŸ¤– Ollama ì„œë²„ ì¢…í•© í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
    connected = await test_ollama_connection()
    
    # ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
    if connected:
        await test_streaming()
    
    print("\n" + "=" * 50)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    if not connected:
        print("\nâš ï¸  Ollama ì„œë²„ ì„¤ì • ê°€ì´ë“œ:")
        print("1. Ollama ì„¤ì¹˜: https://ollama.ai")
        print("2. ì„œë²„ ì‹œì‘: ollama serve")
        print("3. ëª¨ë¸ ì„¤ì¹˜: ollama pull llama3.2:3b")
        print("4. ì´ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ì‹œ ì‹¤í–‰")

if __name__ == "__main__":
    asyncio.run(main())